{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Profile_PowerSGD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Run next cell to overwrite powerSGD_hook, then <u>restart the runtime</u>"
      ],
      "metadata": {
        "id": "yvIlDGrGms6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /usr/local/lib/python3.7/dist-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py\n",
        "import logging\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "\n",
        "from . import default_hooks as default\n",
        "\n",
        "\n",
        "def _orthogonalize(matrix, epsilon=0):\n",
        "    \"\"\"\n",
        "    Applies Gram-Schmidt procedure to orthogonalize a given 2D tensor.\n",
        "    If epsilon is 0, this is equivalent to `torch.qr(matrix, out=(matrix, _))`,\n",
        "    \"\"\"\n",
        "    # TODO Consider using Q = torch.orgqr(*torch.geqrf(A)) to compute the Q of the QR _much_ faster\n",
        "    # and more reliably.\n",
        "    # Works on FP32/64 or complex numbers (does not work for half precision)\n",
        "    num_cols = matrix.shape[1]\n",
        "    for i in range(num_cols):\n",
        "        # Normalize the i'th column.\n",
        "        col = matrix[:, i : i + 1]\n",
        "        # If no epsilon is added here, division by zero may be caused by vanishing gradients.\n",
        "        # This epsilon is not needed if the input matrix covers the gradients of at least one entire layer in the neural network.\n",
        "        if epsilon == 0:\n",
        "            # Note that col ** 2 can underflow/overflow if we use FP16.\n",
        "            # May need to consider multiplying a scaling factor and dividing it later, or using bfloat16 instead.\n",
        "            try:\n",
        "                col /= torch.norm(col)\n",
        "            except ZeroDivisionError:\n",
        "                logging.error(\n",
        "                    \"The matrix to be orthogonalized has at least a column of all 0s. Please set a small value such as 1e-8 \"\n",
        "                    \"as `orthogonalization_epsilon` in PowerSGD state.\"\n",
        "                )\n",
        "                # Recover the values from NaNs to 0s.\n",
        "                col.fill_(0.0)\n",
        "        else:\n",
        "            col /= torch.norm(col) + epsilon\n",
        "        # Project it on the rest and remove it.\n",
        "        if i + 1 < num_cols:\n",
        "            rest = matrix[:, i + 1 :]\n",
        "            rest -= torch.sum(col * rest, dim=0) * col\n",
        "\n",
        "def _should_compress(\n",
        "    num_rows, num_cols, matrix_approximation_rank, min_compression_rate\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns a recommendation as to whether the 2D tensor described by the arguments is worth compressing,\n",
        "    including statistics describing the expected savings from compression.  We consider a tensor worth\n",
        "    compressing when ``min_compression_rate`` < uncompressed size / compressed size, where\n",
        "    uncompressed size = ``num_rows`` * ``num_cols``,\n",
        "    and compressed size = (``num_rows`` + ``num_cols``) * ``matrix_approximation_rank``.\n",
        "\n",
        "    The result of this function is a tuple of the form (compression_recommendation, uncompressed_el_count, compressed_el_count), where:\n",
        "\n",
        "    compresion_recommendation is true if the tensor is worth compressing, and false otherwise (see above);\n",
        "\n",
        "    uncompressed_el_count is the uncompressed element count, i.e. ``num_rows`` * ``num_cols``; and,\n",
        "\n",
        "    compress_el_count is the element count after compression, i.e. (``num_rows`` + ``num_cols``) * ``matrix_approximation_rank``.\n",
        "    \"\"\"  # noqa: B950\n",
        "    uncompressed_size = num_rows * num_cols\n",
        "    compressed_size = (num_rows + num_cols) * matrix_approximation_rank\n",
        "    return (\n",
        "        compressed_size * min_compression_rate < uncompressed_size,\n",
        "        uncompressed_size,\n",
        "        compressed_size,\n",
        "    )\n",
        "\n",
        "\n",
        "def _report_compression_stats(bucket, state):\n",
        "    \"\"\"\n",
        "    Report compression stats at the frequency of `compression_stats_logging_frequency` specified in PowerSGD state.\n",
        "    \"\"\"\n",
        "    if (\n",
        "        bucket.is_last()\n",
        "        and state.iter >= state.next_stats_report\n",
        "    ):\n",
        "        stats = state.compression_stats()\n",
        "        logging.info(\n",
        "            \"Compression stats: iter {}, total before compression {}, total after compression {}, \"\n",
        "            \"rate {}\".format(state.iter, stats[1], stats[2], stats[0])\n",
        "        )\n",
        "        state.next_stats_report = state.iter + state.compression_stats_logging_frequency\n",
        "\n",
        "\n",
        "class PowerSGDState(object):\n",
        "    r\"\"\"\n",
        "    Stores both the algorithm's hyperparameters and the internal state for all the gradients during the training.\n",
        "    Particularly, ``matrix_approximation_rank`` and ``start_powerSGD_iter`` are the main hyperparameters that should be tuned by the user.\n",
        "    For performance, we suggest to keep binary hyperparameters ``use_error_feedback`` and ``warm_start`` on.\n",
        "\n",
        "    1. ``matrix_approximation_rank`` controls the size of compressed low-rank tensors, which determines the compression rate. The lower the rank, the stronger the compression.\n",
        "\n",
        "        1.1. If ``matrix_approximation_rank`` is too low, the full model quality will need more training steps to reach or will never reach and yield loss in accuracy.\n",
        "\n",
        "        1.2. The increase of ``matrix_approximation_rank`` can substantially increase the computation costs of the compression, and the accuracy may not be futher improved beyond a certain ``matrix_approximation_rank`` threshold.\n",
        "\n",
        "    To tune ``matrix_approximation_rank``, we suggest to start from 1 and increase by factors of 2 (like an expoential grid search, 1, 2, 4, ...), until a satisfactory accuracy is reached. Typically only a small value 1-4 is used. For some NLP tasks (as shown in Appendix D of the original paper), this value has been increased to 32.\n",
        "\n",
        "    2. ``start_powerSGD_iter`` defers PowerSGD compression until step ``start_powerSGD_iter``, and vanilla allreduce runs prior to step ``start_powerSGD_iter``. This hybrid scheme of **vanilla allreduce + PowerSGD** can effectively improve the accuracy, even a relatively small ``matrix_approximation_rank`` is used. This is because that, the beginning of training phase is usually very sensitive to inaccurate gradients, and compressing gradients too early may make the training quickly take a suboptimal trajectory, which can result in an irrecoverable impact on the accuracy.\n",
        "\n",
        "    To tune ``start_powerSGD_iter``, we suggest to start with 10% of total training steps, and increase it until a satisfactory accuracy is reached. If there is a warm-up stage in the training, ``start_powerSGD_iter`` typically should be no less than the number of warm-up steps.\n",
        "\n",
        "    3. ``min_compression_rate`` is the minimum compression rate required when a layer is compressed. Due to the computation overheads incurred by the compression, a tensor is worth compressing only if there can be sufficient saving in bandwidth, where ``(num_rows + num_cols) * matrix_approximation_rank * min_compression_rate < num_rows * num_cols``. If the specified compression rate threshold cannot be satisfied, the tensor will be directly allreduced without compression.\n",
        "\n",
        "    Compression statistics are logged every ``compression_stats_logging_frequency`` iterations once PowerSGD compression starts.\n",
        "\n",
        "    4. ``orthogonalization_epsilon`` can be a very small value (e.g., 1e-8) added to every normalized matrix column in orthogonalization step, to prevent div-by-zero error if any column has all 0s. If this can already be prevented (e.g., by batch normalization), an epsilon of 0 is recommended for accuracy.\n",
        "\n",
        "    .. warning ::\n",
        "        If error feedback or warm-up is enabled, the minimum value of ``start_powerSGD_iter`` allowed in DDP is 2.\n",
        "        This is because there is another internal optimization that rebuilds buckets at iteration 1 in DDP,\n",
        "        and this can conflict with any tensor memorized before the rebuild process.\n",
        "    \"\"\"  # noqa: B950\n",
        "\n",
        "    __slots__ = [\n",
        "        \"process_group\",\n",
        "        # The fields below are the hyperparameters that often need to be tuned by the user.\n",
        "        \"matrix_approximation_rank\",\n",
        "        \"start_powerSGD_iter\",\n",
        "        # The fields below are the hyperparameters that seldom need be tuned by the user.\n",
        "        \"min_compression_rate\",\n",
        "        \"orthogonalization_epsilon\",\n",
        "        # The fields below are the binary hyperparameters recommended to be turned on for performance and accuracy.\n",
        "        \"use_error_feedback\",\n",
        "        \"warm_start\",\n",
        "        # The fields below are internal state.\n",
        "        \"rng\",\n",
        "        \"error_dict\",\n",
        "        \"p_memory_dict\",\n",
        "        \"q_memory_dict\",\n",
        "        \"iter\",\n",
        "        # The fields below are for recording compression stats.\n",
        "        \"total_numel_before_compression\",\n",
        "        \"total_numel_after_compression\",\n",
        "        \"compression_stats_logging_frequency\",\n",
        "        \"next_stats_report\",\n",
        "\n",
        "        \"compute_time\",\n",
        "        \"orthogonalization\"\n",
        "    ]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        process_group,\n",
        "        matrix_approximation_rank=1,\n",
        "        start_powerSGD_iter=1_000,\n",
        "        min_compression_rate=2,\n",
        "        use_error_feedback=True,\n",
        "        warm_start=True,\n",
        "        orthogonalization_epsilon=0,\n",
        "        random_seed=0,\n",
        "        compression_stats_logging_frequency=10_000,\n",
        "\n",
        "        orthogonalization = \"qr\"\n",
        "    ):\n",
        "        logging.info(\n",
        "            \"PowerSGD config: matrix_approximation_rank = {}; start_powerSGD_iter = {}; \"\n",
        "            \"min_compression_rate = {}; orthogonalization_epsilon = {}; use_error_feedback = {}; warm_start = {}; \"\n",
        "            \"random_seed = {}; compression_stats_logging_frequency = {}\".format(\n",
        "                matrix_approximation_rank,\n",
        "                start_powerSGD_iter,\n",
        "                min_compression_rate,\n",
        "                orthogonalization_epsilon,\n",
        "                use_error_feedback,\n",
        "                warm_start,\n",
        "                random_seed,\n",
        "                compression_stats_logging_frequency,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.process_group = process_group\n",
        "        self.matrix_approximation_rank = matrix_approximation_rank\n",
        "        # Deferring PowerSGD compression util step 'start_powerSGD_iter' can have two advantages:\n",
        "        # 1) It turns out that PowerSGD may lead to a non-trivial accuracy loss,\n",
        "        # even if the matrix approximation rank is increased to a large value.\n",
        "        # To mitigate the accuracy loss, a simple yet effective way is mixing vanilla allreduce\n",
        "        # (or a more conservative compression such as FP16 compression) with PowerSGD.\n",
        "        # 2) There is an internal optimization of rebuilding buckets process in DDP,\n",
        "        # in order to save the memory space.\n",
        "        # This step takes place after the first iteration.\n",
        "        # However, this means that the shape of input bucketized tensors is subject to change,\n",
        "        # which will complicate the implementations of error feedback and warm-up.\n",
        "        # Running vanilla allreduce in the first few iterations can avoid this complexity.\n",
        "        if (use_error_feedback or warm_start) and start_powerSGD_iter <= 1:\n",
        "            raise ValueError(\n",
        "                \"Expect `start_powerSGD_iter` > 1 if `use_error_feedback` or `warm_start` is enabled, \"\n",
        "                \"because PowerSGD can only be applied after the first two iterations in DDP.\"\n",
        "            )\n",
        "        self.start_powerSGD_iter = start_powerSGD_iter\n",
        "        self.min_compression_rate = min_compression_rate\n",
        "        # Error feedback is usually crucial for both for convergence and generalization,\n",
        "        # because PowerSGD is a biased compressor,\n",
        "        # i.e., compressing and decompressing a random gradient does not yield the original in expectation.\n",
        "        # This mechanism requires a temporary copy of the input gradients,\n",
        "        # so it increases the peak memory consumption by the size of the gradient tensor.\n",
        "        # However, if the target matrices are known to be exactly low-ranked (instead of just low stable rank),\n",
        "        # sometimes it is possible to converge to the optima without error feedback.\n",
        "        # See: http://proceedings.mlr.press/v54/yurtsever17a/yurtsever17a.pdf\n",
        "        self.use_error_feedback = use_error_feedback\n",
        "        # Warm-start reuses P(s) and Q(s) from the previous iteration.\n",
        "        # This can improve the approximation quality and hence improve the accuracy.\n",
        "        # Additionally, by avoiding the initialization of these low-rank tensors at every step,\n",
        "        # this can also accelerate training.\n",
        "        # However, this is at the cost of extra memory.\n",
        "        self.warm_start = warm_start\n",
        "        # Can use a very small value to prevent div-by-zero error caused by orthogonalization of vanishing gradients.\n",
        "        self.orthogonalization_epsilon = orthogonalization_epsilon\n",
        "        # The purpose of this RNG is to generate different random seeds for initializing Q across iterations,\n",
        "        # but in the same order for all the DDP replicas.\n",
        "        # Different random seeds across iterations indicate different 'projections' of the gradients at different SGD steps.\n",
        "        # If the same random projection is used,\n",
        "        # there will be differences between the gradients that are never synchronized.\n",
        "        self.rng = np.random.RandomState(random_seed)\n",
        "        # Since there is only a single state instance for all the input buckets,\n",
        "        # need to maintain a dictionary that maps each bucket index to the local error.\n",
        "        self.error_dict = {}\n",
        "        self.p_memory_dict = {}\n",
        "        self.q_memory_dict = {}\n",
        "        # Iteration/step in the training loop.\n",
        "        self.iter = 0\n",
        "        # Compression stats accumulators\n",
        "        self.total_numel_before_compression = 0\n",
        "        self.total_numel_after_compression = 0\n",
        "        # We'll report compression stats every 'compression_stats_logging_frequency' iterations\n",
        "        # Note that we always report compression stats at least once.\n",
        "        self.compression_stats_logging_frequency = max(\n",
        "            1, compression_stats_logging_frequency\n",
        "        )\n",
        "        self.next_stats_report = 0\n",
        "        \n",
        "        self.compute_time = 0\n",
        "        self.orthogonalization = orthogonalization\n",
        "\n",
        "    def maybe_increase_iter(self, bucket):\n",
        "        # Since bucket 0 is the last bucket to allreduce in an iteration.\n",
        "        # Only increase `iter` when bucket 0 is processed.\n",
        "        if bucket.is_last():\n",
        "            self.iter += 1\n",
        "\n",
        "        if self.iter == self.start_powerSGD_iter:\n",
        "            logging.info(\n",
        "                \"Start to apply PowerSGD after {} iterations.\".format(self.iter)\n",
        "            )\n",
        "\n",
        "    def compression_stats(self):\n",
        "        r\"\"\"\n",
        "        Returns the latest compression statistics as a tuple of the form (compress_rate, numel_before_compression, numel_after_compression), where:\n",
        "\n",
        "        compress_rate is the effective compression rate i.e. (number of elements before compression) / (number of elements after compression);\n",
        "\n",
        "        numel_before_compression is the total number of elements before compression was applied; and,\n",
        "\n",
        "        numel_after_compression is the total number of elements after compression was applied.\n",
        "        \"\"\"  # noqa: B950\n",
        "        compress_rate = (\n",
        "            self.total_numel_before_compression / self.total_numel_after_compression\n",
        "            if self.total_numel_after_compression > 0\n",
        "            else 0\n",
        "        )\n",
        "        return (\n",
        "            compress_rate,\n",
        "            self.total_numel_before_compression,\n",
        "            self.total_numel_after_compression,\n",
        "        )\n",
        "\n",
        "\n",
        "def powerSGD_hook(\n",
        "    state: PowerSGDState, bucket: dist.GradBucket\n",
        ") -> torch.futures.Future[torch.Tensor]:\n",
        "    r\"\"\"\n",
        "    This DDP communication hook implements PowerSGD gradient compression\n",
        "    algorithm described in the `paper <https://arxiv.org/abs/1905.13727>`_.\n",
        "    Once gradient tensors are aggregated across all workers, this hook applies\n",
        "    compression as follows:\n",
        "\n",
        "    1. Views the input flattened 1D gradient tensor as a list of per-parameter tensors, and divides all the tensors into two groups:\n",
        "\n",
        "        1.1 The tensors that should be compressed before allreduce, because the compression can give enough saving in bandwidth.\n",
        "\n",
        "        1.2 Rest of the tensors will be directly allreduced without compression, including all the vector tensors (for biases).\n",
        "\n",
        "    2. Handles uncompressed tensors:\n",
        "\n",
        "        2.1. Allocate contiguous memory for those uncompressed tensors, and allreduces all the uncompressed tensors as a batch, without compression;\n",
        "\n",
        "        2.2. Copies the individual uncompressed tensors from the contiguous memory back to the input tensor.\n",
        "\n",
        "    3. Handles the tensors that should be compressed by PowerSGD compression:\n",
        "\n",
        "        3.1. For each tensor M, creates two low-rank tensors P and Q for decomposing M,\n",
        "        such that M = PQ^T, where Q is initialized from a standard normal distribution and orthogonalized;\n",
        "\n",
        "        3.2. Computes each P in Ps, which is equal to MQ;\n",
        "\n",
        "        3.3. Allreduces Ps as a batch;\n",
        "\n",
        "        3.4. Orthogonalizes each P in Ps;\n",
        "\n",
        "        3.5. Computes each Q in Qs, which is approximately equal to M^TP;\n",
        "\n",
        "        3.6. Allreduces Qs as a batch;\n",
        "\n",
        "        3.7. Computes each M among all the compressed tensors, which is approximately equal to PQ^T.\n",
        "\n",
        "    Note that this communication hook enforces vanilla allreduce for the first ``state.start_powerSGD_iter`` iterations.\n",
        "    This not only gives the user more control over the tradeoff between speedup and accuracy,\n",
        "    but also helps abstract away some complexity of the internal optimization of DDP for future communication hook developers.\n",
        "\n",
        "    Args:\n",
        "        state (PowerSGDState): State information to configure the compression rate and support error feedback, warm start, etc.\n",
        "            To tune the compression configs, mainly need to tune ``matrix_approximation_rank``, ``start_powerSGD_iter``\n",
        "            and ``min_compression_rate``.\n",
        "        bucket (dist.GradBucket): Bucket that stores a 1D flattened gradient tensor that batches multiple per-variable tensors.\n",
        "            Note that since DDP comm hook only supports single process single device mode,\n",
        "            only exactly one tensor is stored in this bucket.\n",
        "\n",
        "    Returns:\n",
        "        Future handler of the communication, which updates the gradients in place.\n",
        "\n",
        "    Example::\n",
        "        >>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1,\n",
        "                                  start_powerSGD_iter=10, min_compression_rate=0.5)\n",
        "        >>> ddp_model.register_comm_hook(state, powerSGD_hook)\n",
        "    \"\"\"  # noqa: B950\n",
        "    start_time = torch.cuda.Event(enable_timing=True)\n",
        "    end_time = torch.cuda.Event(enable_timing=True)\n",
        "    start_time.record()\n",
        "\n",
        "    process_group = state.process_group\n",
        "    group_to_use = process_group if process_group is not None else dist.group.WORLD\n",
        "    world_size = group_to_use.size()\n",
        "\n",
        "    # The input tensor is a flattened 1D tensor.\n",
        "    input_tensor = bucket.buffer()\n",
        "\n",
        "    # Run vanilla allreduce in the first `start_powerSGD_iter` iterations.\n",
        "    if state.iter < state.start_powerSGD_iter:\n",
        "        state.maybe_increase_iter(bucket)\n",
        "        return default._allreduce_fut(group_to_use, input_tensor)\n",
        "\n",
        "    # Apply PowerSGD after `start_powerSGD_iter` iterations.\n",
        "    device = input_tensor.device\n",
        "    dtype = input_tensor.dtype\n",
        "\n",
        "    # Incorporate the error from the previous state into the gradients.\n",
        "    bucket_index = bucket.index()\n",
        "    input_tensor_cp = None\n",
        "    total_length = input_tensor.shape[0]\n",
        "    if state.use_error_feedback:\n",
        "        if bucket_index in state.error_dict:\n",
        "            input_tensor.add_(state.error_dict[bucket_index])\n",
        "        else:\n",
        "            logging.info(\n",
        "                \"A zero tensor of length {} that represents local error is created.\".format(\n",
        "                    total_length\n",
        "                )\n",
        "            )\n",
        "            state.error_dict[bucket_index] = torch.zeros(\n",
        "                total_length, device=device, dtype=dtype\n",
        "            )\n",
        "\n",
        "        # Keep a copy of the input tensor,\n",
        "        # so that we can compute the local error caused by compression later,\n",
        "        # by comparing this copy and the input tensor updated after decompression.\n",
        "        input_tensor_cp = torch.clone(input_tensor).detach()\n",
        "\n",
        "    # Unflatten the input tensor into per-parameter tensors, for layer-wise compression.\n",
        "    tensors = bucket.gradients()\n",
        "\n",
        "    # Step I: Divide all the tensors into two groups,\n",
        "    # one will be compressed before allreduce and the other will be directly allreduced without compression.\n",
        "    tensors_to_compress, uncompressed_tensors = [], []\n",
        "    total_Ps_size = 0\n",
        "    total_Qs_size = 0\n",
        "    for tensor in tensors:\n",
        "        matrix = tensor.view(tensor.shape[0], -1)\n",
        "        n, m = matrix.shape\n",
        "        matrix_approximation_rank = min(n, m, state.matrix_approximation_rank)\n",
        "        compress_test = _should_compress(\n",
        "            n, m, matrix_approximation_rank, state.min_compression_rate\n",
        "        )\n",
        "        state.total_numel_before_compression += compress_test[1]\n",
        "        if compress_test[0]:\n",
        "            tensors_to_compress.append(matrix)\n",
        "            total_Ps_size += n * matrix_approximation_rank\n",
        "            total_Qs_size += m * matrix_approximation_rank\n",
        "            state.total_numel_after_compression += compress_test[2]\n",
        "        else:\n",
        "            uncompressed_tensors.append(tensor)\n",
        "            state.total_numel_after_compression += compress_test[1]\n",
        "\n",
        "    _report_compression_stats(bucket, state)\n",
        "\n",
        "    # Step II: Handle uncompressed tensors.\n",
        "    # Allocate contiguous memory for these tensors to allreduce efficiently.\n",
        "    uncompressed_tensors_memory = (\n",
        "        torch.cat([tensor.view(-1) for tensor in uncompressed_tensors])\n",
        "        if uncompressed_tensors\n",
        "        else torch.tensor([], device=device, dtype=dtype)\n",
        "    )\n",
        "\n",
        "    # Step III: Handle the tensors that should be compressed.\n",
        "    # Allocate contiguous memory for Ps and Qs to allreduce efficiently.\n",
        "    # If warm-start is enabled, reuse Ps and Qs from the previous iteration if possible.\n",
        "    # The memory spaces of Ps and Qs need to be allocated in the first iteration when PowerSGD is applied.\n",
        "    need_randomize_qs = False\n",
        "    if not state.warm_start or bucket_index not in state.p_memory_dict:\n",
        "        need_randomize_qs = True\n",
        "        # If warm-start is disabled, low-rank tensors will be initialized at every step.\n",
        "        # Only log this if warm-start to avoid spamming.\n",
        "        if state.warm_start:\n",
        "            logging.info(\n",
        "                \"Allocating contiguous memory of length {} for Ps, and of length {} for Qs, respectively.\".format(\n",
        "                    total_Ps_size, total_Qs_size\n",
        "                )\n",
        "            )\n",
        "        state.p_memory_dict[bucket_index] = torch.empty(\n",
        "            total_Ps_size, device=device, dtype=dtype\n",
        "        )\n",
        "        state.q_memory_dict[bucket_index] = torch.empty(\n",
        "            total_Qs_size, device=device, dtype=dtype\n",
        "        )\n",
        "\n",
        "    # Create Ps and Qs that point to the allocated memory.\n",
        "    ps = []\n",
        "    qs = []\n",
        "    p_idx = 0\n",
        "    q_idx = 0\n",
        "    for tensor in tensors_to_compress:\n",
        "        n, m = tensor.shape\n",
        "        matrix_approximation_rank = min(n, m, state.matrix_approximation_rank)\n",
        "        ps.append(\n",
        "            state.p_memory_dict[bucket_index][\n",
        "                p_idx : p_idx + n * matrix_approximation_rank\n",
        "            ].view(n, matrix_approximation_rank)\n",
        "        )\n",
        "        qs.append(\n",
        "            state.q_memory_dict[bucket_index][\n",
        "                q_idx : q_idx + m * matrix_approximation_rank\n",
        "            ].view(m, matrix_approximation_rank)\n",
        "        )\n",
        "        p_idx += n * matrix_approximation_rank\n",
        "        q_idx += m * matrix_approximation_rank\n",
        "\n",
        "    # If warm-start is enabled, reuse Qs from the previous iteration if possible and skip filling random values.\n",
        "    # The exception is the first iteration when PowerSGD is applied.\n",
        "    if not need_randomize_qs:\n",
        "        for q in qs:\n",
        "          if state.orthogonalization == 'qr':\n",
        "            torch.linalg.qr(q, out=(q, torch.empty(q.shape[1], q.shape[1], device=device, dtype=dtype)))\n",
        "          else:\n",
        "            _orthogonalize(q, epsilon = state.orthogonalization_epsilon)\n",
        "    else:\n",
        "        with torch.random.fork_rng(devices=[]):\n",
        "            # Fork this RNG to avoid changing the seed globally and affecting the random sampling anywhere else in the training.\n",
        "            # The seed makes sure that the initial random values are the same across all the DDP replicas.\n",
        "            # This seed should differ at every step.\n",
        "            # Since it is very slow to fork RNG state across all the CUDA devices,\n",
        "            # only fork on CPU and then move the generated tensor to the CUDA device (by overwriting q).\n",
        "            torch.manual_seed(state.rng.randint(1_000_000_000))\n",
        "            for q in qs:\n",
        "                q.copy_(\n",
        "                    torch.randn(\n",
        "                        *q.shape,\n",
        "                        device=\"cpu\",\n",
        "                        dtype=dtype,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                if state.orthogonalization == 'qr':\n",
        "                  torch.linalg.qr(q, out=(q, torch.empty(q.shape[1], q.shape[1], device=device, dtype=dtype)))\n",
        "                else:\n",
        "                  _orthogonalize(q, epsilon = state.orthogonalization_epsilon)\n",
        "\n",
        "\n",
        "    # Compute Ps.\n",
        "    for tensor, q, p in zip(tensors_to_compress, qs, ps):\n",
        "        torch.matmul(tensor, q, out=p)\n",
        "\n",
        "    # This allreduce is only applied to uncompressed tensors,\n",
        "    # so it should have been kicked off before the above computation on the compressed tensors to hide more communication costs.\n",
        "    # However, this somehow requires a separate future chain at this time.\n",
        "    allreduce_contiguous_uncompressed_tensors_fut = dist.all_reduce(\n",
        "        uncompressed_tensors_memory, group=group_to_use, async_op=True\n",
        "    ).get_future()\n",
        "\n",
        "    def unpack_uncompressed_tensors_and_allreduce_ps(fut):\n",
        "        uncompressed_tensors_memory = fut.value()[0].div_(world_size)\n",
        "        idx = 0\n",
        "        for tensor in uncompressed_tensors:\n",
        "            tensor.copy_(\n",
        "                uncompressed_tensors_memory[idx : idx + tensor.numel()].view_as(tensor)\n",
        "            )\n",
        "            idx += tensor.numel()\n",
        "\n",
        "        # Since these Ps will be orthogonalized later, no need to divide them by world size.\n",
        "        return (\n",
        "            dist.all_reduce(\n",
        "                state.p_memory_dict[bucket_index], group=group_to_use, async_op=True\n",
        "            )\n",
        "            .get_future()\n",
        "            .wait()[0]\n",
        "        )\n",
        "\n",
        "    def compute_qs(fut):\n",
        "        state.p_memory_dict[bucket_index] = fut.value()\n",
        "        for p in ps:\n",
        "          if state.orthogonalization == 'qr':\n",
        "            torch.linalg.qr(p, out=(p, torch.empty(p.shape[1], p.shape[1], device=device, dtype=dtype)))\n",
        "          else:\n",
        "            _orthogonalize(p, epsilon = state.orthogonalization_epsilon)\n",
        "\n",
        "        # Compute Qs.\n",
        "        for tensor, p, q in zip(tensors_to_compress, ps, qs):\n",
        "            torch.matmul(tensor.t(), p, out=q)\n",
        "\n",
        "        # TODO: The above procedure does two matmul+allreduce steps per iteration --\n",
        "        # one left multiplication and one right multiplication.\n",
        "        # For warm-start, can take one such step at a time, and alternate between them.\n",
        "\n",
        "        # Allreduce Qs.\n",
        "        return (\n",
        "            dist.all_reduce(\n",
        "                state.q_memory_dict[bucket_index], group=group_to_use, async_op=True\n",
        "            )\n",
        "            .get_future()\n",
        "            .wait()[0]\n",
        "        )\n",
        "\n",
        "    def decompress(fut):\n",
        "        state.q_memory_dict[bucket_index] = fut.value().div_(world_size)\n",
        "\n",
        "        for p, q, tensor in zip(ps, qs, tensors_to_compress):\n",
        "            torch.matmul(p, q.t(), out=tensor)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize(device)\n",
        "\n",
        "        if state.use_error_feedback:\n",
        "            # Memorize the local errors.\n",
        "            state.error_dict[bucket_index] = input_tensor_cp - input_tensor\n",
        "        if not state.warm_start:\n",
        "            state.p_memory_dict.clear()\n",
        "            state.q_memory_dict.clear()\n",
        "\n",
        "        state.maybe_increase_iter(bucket)\n",
        "\n",
        "        return input_tensor\n",
        "\n",
        "    def save_time(_):\n",
        "      end_time.record()\n",
        "      torch.cuda.synchronize()\n",
        "      state.compute_time = start_time.elapsed_time(end_time)\n",
        "\n",
        "      return input_tensor\n",
        "\n",
        "    return (\n",
        "        allreduce_contiguous_uncompressed_tensors_fut.then(\n",
        "            unpack_uncompressed_tensors_and_allreduce_ps\n",
        "        )\n",
        "        .then(compute_qs)\n",
        "        .then(decompress)\n",
        "        .then(save_time)\n",
        "    )\n",
        "\n",
        "\n",
        "def batched_powerSGD_hook(\n",
        "    state: PowerSGDState, bucket: dist.GradBucket\n",
        ") -> torch.futures.Future[torch.Tensor]:\n",
        "    r\"\"\"\n",
        "    This DDP communication hook implements a simplified PowerSGD gradient compression\n",
        "    algorithm described in the `paper <https://arxiv.org/abs/1905.13727>`_.\n",
        "    This variant does not compress the gradients layer by layer,\n",
        "    but instead compresses the flattened input tensor that batches all the gradients.\n",
        "    Therefore, it is **faster** than :meth:`powerSGD_hook`,\n",
        "    but usually results in a **much lower accuracy**, unless ``matrix_approximation_rank`` is 1.\n",
        "\n",
        "    .. warning ::\n",
        "        Increasing ``matrix_approximation_rank`` here may not necessarily increase the accuracy,\n",
        "        because batching per-parameter tensors without column/row alignment can destroy low-rank structure.\n",
        "        Therefore, the user should always consider :meth:`powerSGD_hook` first,\n",
        "        and only consider this variant when a satisfactory accuracy can be achieved when ``matrix_approximation_rank`` is 1.\n",
        "\n",
        "    Once gradient tensors are aggregated across all workers, this hook applies\n",
        "    compression as follows:\n",
        "\n",
        "    1. Views the input flattened 1D gradient tensor as a square-shaped tensor M with 0 paddings;\n",
        "\n",
        "    2. Creates two low-rank tensors P and Q for decomposing M, such that M = PQ^T, where Q is initialized from a standard normal distribution and orthogonalized;\n",
        "\n",
        "    3. Computes P, which is equal to MQ;\n",
        "\n",
        "    4. Allreduces P;\n",
        "\n",
        "    5. Orthogonalizes P;\n",
        "\n",
        "    6. Computes Q, which is approximately equal to M^TP;\n",
        "\n",
        "    7. Allreduces Q;\n",
        "\n",
        "    8. Computes M, which is approximately equal to PQ^T.\n",
        "\n",
        "    9. Truncates the input tensor to the original length.\n",
        "\n",
        "    Note that this communication hook enforces vanilla allreduce for the first ``state.start_powerSGD_iter`` iterations.\n",
        "    This not only gives the user more control over the tradeoff between speedup and accuracy,\n",
        "    but also helps abstract away some complexity of the internal optimization of DDP for future communication hook developers.\n",
        "\n",
        "    Args:\n",
        "        state (PowerSGDState): State information to configure the compression rate and support error feedback, warm start, etc.\n",
        "            To tune the compression configs, mainly need to tune ``matrix_approximation_rank`` and ``start_powerSGD_iter``.\n",
        "        bucket (dist.GradBucket): Bucket that stores a 1D flattened gradient tensor that batches multiple per-variable tensors.\n",
        "            Note that since DDP comm hook only supports single process single device mode,\n",
        "            only exactly one tensor is stored in this bucket.\n",
        "\n",
        "    Returns:\n",
        "        Future handler of the communication, which updates the gradients in place.\n",
        "\n",
        "    Example::\n",
        "        >>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1)\n",
        "        >>> ddp_model.register_comm_hook(state, batched_powerSGD_hook)\n",
        "    \"\"\"  # noqa: B950\n",
        "    start_time = torch.cuda.Event(enable_timing=True)\n",
        "    end_time = torch.cuda.Event(enable_timing=True)\n",
        "    start_time.record()\n",
        "\n",
        "    process_group = state.process_group\n",
        "    group_to_use = process_group if process_group is not None else dist.group.WORLD\n",
        "    world_size = group_to_use.size()\n",
        "\n",
        "    # The input tensor is a flattened 1D tensor.\n",
        "    input_tensor = bucket.buffer()\n",
        "\n",
        "    # Run vanilla allreduce in the first `start_powerSGD_iter` iterations.\n",
        "    if state.iter < state.start_powerSGD_iter:\n",
        "        state.maybe_increase_iter(bucket)\n",
        "        return default._allreduce_fut(group_to_use, input_tensor)\n",
        "\n",
        "    # Apply PowerSGD after `start_powerSGD_iter` iterations.\n",
        "    device = input_tensor.device\n",
        "    total_length = input_tensor.shape[0]\n",
        "    state.total_numel_before_compression += total_length\n",
        "\n",
        "    # View the input tensor as a 2D square-shape tensor, and pad 0s if necessary.\n",
        "    square_side_length = math.ceil(math.sqrt(total_length))\n",
        "    state.total_numel_after_compression += (\n",
        "        square_side_length * state.matrix_approximation_rank * 2\n",
        "    )\n",
        "    padded_total_length = square_side_length ** 2\n",
        "    input_tensor.resize_(padded_total_length)\n",
        "    input_tensor[total_length:padded_total_length].fill_(0)\n",
        "\n",
        "    _report_compression_stats(bucket, state)\n",
        "\n",
        "    # Incorporate the error from the previous state into the gradients.\n",
        "    bucket_index = bucket.index()\n",
        "    input_tensor_cp = None\n",
        "    if state.use_error_feedback:\n",
        "        if bucket_index in state.error_dict:\n",
        "            input_tensor.add_(state.error_dict[bucket_index])\n",
        "        else:\n",
        "            logging.info(\n",
        "                \"A zero tensor of length {} that represents local error is created.\".format(\n",
        "                    padded_total_length\n",
        "                )\n",
        "            )\n",
        "            state.error_dict[bucket_index] = torch.zeros(\n",
        "                padded_total_length, device=device, dtype=input_tensor.dtype\n",
        "            )\n",
        "\n",
        "        # Keep a copy of the input tensor,\n",
        "        # so that we can compute the local error caused by compression later,\n",
        "        # by comparing this copy and the input tensor updated after decompression.\n",
        "        input_tensor_cp = torch.clone(input_tensor).detach()\n",
        "    matrix = input_tensor.view(square_side_length, square_side_length)\n",
        "\n",
        "    # Reuse P and Q from the previous iteration if possible.\n",
        "    # The memory spaces of P and Q need to be allocated in the first iteration when PowerSGD is applied.\n",
        "    if not state.warm_start or bucket_index not in state.p_memory_dict:\n",
        "        # If warm-start is disabled, low-rank tensors will be initialized at every step.\n",
        "        # Only log this if warm-start to avoid spamming.\n",
        "        if state.warm_start:\n",
        "            logging.info(\n",
        "                \"Initializing low-rank tensors P and Q, each of which has a shape of {} x {}.\".format(\n",
        "                    square_side_length, state.matrix_approximation_rank\n",
        "                )\n",
        "            )\n",
        "\n",
        "        def create_low_rank_tensor(fill_random_values, rng):\n",
        "            \"Returns a low-rank 2D tensor of square_side_length * matrix_approximation_rank.\"\n",
        "            if fill_random_values:\n",
        "                with torch.random.fork_rng(devices=[]):\n",
        "                    # Fork this RNG to avoid changing the seed globally and affecting the random sampling\n",
        "                    # anywhere else in the training.\n",
        "                    # The seed makes sure that the initial random values are the same across all the DDP replicas.\n",
        "                    # This seed should differ at every step.\n",
        "                    # Since it is very slow to fork RNG state across all the CUDA devices,\n",
        "                    # only fork on CPU and then move the generated tensor to the CUDA device.\n",
        "                    torch.manual_seed(rng.randint(1_000_000_000))\n",
        "                    return torch.randn(\n",
        "                        square_side_length,\n",
        "                        state.matrix_approximation_rank,\n",
        "                        device=\"cpu\",\n",
        "                        dtype=input_tensor.dtype,\n",
        "                    ).to(device)\n",
        "            else:\n",
        "                return torch.empty(\n",
        "                    square_side_length,\n",
        "                    state.matrix_approximation_rank,\n",
        "                    device=device,\n",
        "                    dtype=input_tensor.dtype,\n",
        "                )\n",
        "\n",
        "        state.p_memory_dict[bucket_index] = create_low_rank_tensor(\n",
        "            fill_random_values=False, rng=state.rng\n",
        "        )\n",
        "        state.q_memory_dict[bucket_index] = create_low_rank_tensor(\n",
        "            fill_random_values=True, rng=state.rng\n",
        "        )\n",
        "\n",
        "    if state.orthogonalization == 'qr':\n",
        "      torch.linalg.qr(\n",
        "          state.q_memory_dict[bucket_index], \n",
        "          out=(\n",
        "              state.q_memory_dict[bucket_index], \n",
        "              torch.empty(state.matrix_approximation_rank, state.matrix_approximation_rank, device=device)\n",
        "          )\n",
        "      )\n",
        "    else:\n",
        "      _orthogonalize(state.q_memory_dict[bucket_index], epsilon=state.orthogonalization_epsilon)\n",
        "\n",
        "    torch.matmul(\n",
        "        matrix, state.q_memory_dict[bucket_index], out=state.p_memory_dict[bucket_index]\n",
        "    )\n",
        "    allreduce_p_fut = dist.all_reduce(\n",
        "        state.p_memory_dict[bucket_index], group=group_to_use, async_op=True\n",
        "    ).get_future()\n",
        "\n",
        "    def compute_q(fut):\n",
        "        state.p_memory_dict[bucket_index] = fut.value()[0]\n",
        "\n",
        "        if state.orthogonalization == 'qr':\n",
        "          torch.linalg.qr(\n",
        "              state.p_memory_dict[bucket_index],\n",
        "              out=(\n",
        "                  state.p_memory_dict[bucket_index],\n",
        "                  torch.empty(state.matrix_approximation_rank, state.matrix_approximation_rank, device=device)\n",
        "              ) \n",
        "          )\n",
        "        else:\n",
        "          _orthogonalize(state.p_memory_dict[bucket_index], epsilon = state.orthogonalization_epsilon)\n",
        "\n",
        "        torch.matmul(\n",
        "            matrix.t(),\n",
        "            state.p_memory_dict[bucket_index],\n",
        "            out=state.q_memory_dict[bucket_index],\n",
        "        )\n",
        "\n",
        "        # TODO: The above procedure does two matmul+allreduce steps per iteration --\n",
        "        # one left multiplication and one right multiplication.\n",
        "        # For warm-start, can take one such step at a time, and alternate between them.\n",
        "\n",
        "        return (\n",
        "            dist.all_reduce(\n",
        "                state.q_memory_dict[bucket_index], group=group_to_use, async_op=True\n",
        "            )\n",
        "            .get_future()\n",
        "            .wait()[0]\n",
        "        )\n",
        "\n",
        "    def decompress(fut):\n",
        "        state.q_memory_dict[bucket_index] = fut.value().div_(world_size)\n",
        "        torch.matmul(\n",
        "            state.p_memory_dict[bucket_index],\n",
        "            state.q_memory_dict[bucket_index].t(),\n",
        "            out=matrix,\n",
        "        )\n",
        "\n",
        "        if state.use_error_feedback:\n",
        "            # Memorize the local errors.\n",
        "            state.error_dict[bucket_index] = input_tensor_cp - input_tensor\n",
        "        # Removing this seemingly unnecessary sync somehow may cause faliures.\n",
        "        # See: https://github.com/pytorch/pytorch/pull/54838\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize(device)\n",
        "        if not state.warm_start:\n",
        "            state.p_memory_dict.clear()\n",
        "            state.q_memory_dict.clear()\n",
        "        ret = input_tensor.resize_(total_length)\n",
        "\n",
        "        state.maybe_increase_iter(bucket)\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def save_time(_):\n",
        "      end_time.record()\n",
        "      torch.cuda.synchronize()\n",
        "      state.compute_time = start_time.elapsed_time(end_time)\n",
        "\n",
        "      return input_tensor\n",
        "\n",
        "    return allreduce_p_fut.then(compute_q).then(decompress).then(save_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KZ_pVsPmQPj",
        "outputId": "9b2b4027-5cbd-463c-87b6-c638941bcce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /usr/local/lib/python3.7/dist-packages/torch/distributed/algorithms/ddp_comm_hooks/powerSGD_hook.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "XkxRnH2_uPY6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8B1pMUBFz55"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import torch.profiler\n",
        "\n",
        "import torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook as powerSGD\n",
        "\n",
        "import os\n",
        "\n",
        "torch.manual_seed(42);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dist variables"
      ],
      "metadata": {
        "id": "NHKeqhLkzRnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MASTER_ADDR'] = 'localhost'\n",
        "os.environ['MASTER_PORT'] = '29500'\n",
        "\n",
        "torch.distributed.init_process_group('nccl', rank=0, world_size=1)\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "_vyz9kUAyvVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Profile functions"
      ],
      "metadata": {
        "id": "t9hwUGDBxM-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warmup = 5\n",
        "active = 10"
      ],
      "metadata": {
        "id": "oLMB6Vax-XSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_time_error(type_ort, model, train_set, rank, batch_size):\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  ddp_model = nn.parallel.DistributedDataParallel(module=model.cuda(device))\n",
        "  state = powerSGD.PowerSGDState(\n",
        "      process_group=None, \n",
        "      matrix_approximation_rank=rank, \n",
        "      min_compression_rate=1, \n",
        "      start_powerSGD_iter=2,\n",
        "      orthogonalization=type_ort\n",
        "  )\n",
        "  ddp_model.register_comm_hook(state, powerSGD.batched_powerSGD_hook)\n",
        "  ddp_model.train()\n",
        "\n",
        "  optimizer = torch.optim.Adam(ddp_model.parameters())\n",
        "  criterion = torch.nn.CrossEntropyLoss().cuda(device)\n",
        "\n",
        "  def train_step(data):\n",
        "    inputs, labels = data[0].to(device=device), data[1].to(device=device)\n",
        "    outputs = ddp_model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  total_error = 0\n",
        "  total_time = 0\n",
        "  for step, batch_data in enumerate(train_loader):\n",
        "    if step < warmup:\n",
        "      train_step(batch_data)\n",
        "    elif step < warmup + active:\n",
        "      train_step(batch_data)\n",
        "\n",
        "      for err in state.error_dict.values():\n",
        "        total_error += torch.linalg.norm(err)\n",
        "\n",
        "      total_time += state.compute_time\n",
        "\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  \n",
        "  return total_error.item() / active, total_time / active\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "8nEjPlff2s2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "!pip install wandb\n",
        "!wandb login\n",
        "\n",
        "import wandb\n",
        "wandb.init(project=\"PowerSGD\", entity=\"younis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "u-Ep8LH4aaeu",
        "outputId": "581b4b84-de36-441c-c2c2-2c8b48e11abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.26)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myounis\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myounis\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/younis/PowerSGD/runs/j5ugp6j4\" target=\"_blank\">azure-haze-11</a></strong> to <a href=\"https://wandb.ai/younis/PowerSGD\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f7e3b5a2110>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/younis/PowerSGD/runs/j5ugp6j4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get dataset and sample model"
      ],
      "metadata": {
        "id": "nsxX60I2uSRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "     T.Resize(224),\n",
        "     T.ToTensor(),\n",
        "     T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "train_set = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZKfA8ctGLg8",
        "outputId": "1f4309e5-8bcb-4681-b469-bae718da3f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_net(resnet): \n",
        "  resnet.conv1.weight.data.fill_(0)\n",
        "  resnet.layer1[0].conv1.weight.data.fill_(0)\n",
        "  resnet.layer1[0].conv2.weight.data.fill_(0)\n",
        "  resnet.layer1[1].conv1.weight.data.fill_(0)\n",
        "  resnet.layer1[1].conv2.weight.data.fill_(0)\n",
        "\n",
        "  resnet.layer2[0].conv1.weight.data.fill_(0)\n",
        "  resnet.layer2[0].conv2.weight.data.fill_(0)\n",
        "  resnet.layer2[1].conv1.weight.data.fill_(0)\n",
        "  resnet.layer2[1].conv2.weight.data.fill_(0)\n",
        "\n",
        "  resnet.layer3[0].conv1.weight.data.fill_(0)\n",
        "  resnet.layer3[0].conv2.weight.data.fill_(0)\n",
        "  resnet.layer3[1].conv1.weight.data.fill_(0)\n",
        "  resnet.layer3[1].conv2.weight.data.fill_(0)\n",
        "\n",
        "  resnet.layer4[0].conv1.weight.data.fill_(0)\n",
        "  resnet.layer4[0].conv2.weight.data.fill_(0)\n",
        "  resnet.layer4[1].conv1.weight.data.fill_(0)\n",
        "  resnet.layer4[1].conv2.weight.data.fill_(0)"
      ],
      "metadata": {
        "id": "Af1Iow1YQXVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "types = ['qr', 'Gram-Schmidt']\n",
        "\n",
        "models = {\n",
        "    'ResNet18-batched': lambda : torchvision.models.resnet18(pretrained = False),\n",
        "    'ResNet50-batched': lambda : torchvision.models.resnet50(pretrained = False),\n",
        "    'ResNext101-batched': lambda : torchvision.models.resnext101_32x8d(pretrained = False),\n",
        "    #'BERT': lambda : BertModel(BertConfig())\n",
        "}\n",
        "\n",
        "ranks = [1, 2, 4, 8, 16]\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "for name, model_f in models.items():\n",
        "  errors = [[], []]\n",
        "  times = [[], []]\n",
        "  for i, type_ in enumerate(types):\n",
        "    model = model_f()\n",
        "\n",
        "    for r in ranks:\n",
        "      error, time = record_time_error(type_, model, train_set, r, batch_size)\n",
        "      times[i].append(time)\n",
        "      errors[i].append(error)\n",
        "\n",
        "  print(errors)\n",
        "  print(times)\n",
        "  wandb.log(\n",
        "      {f\"error-{name}\" : wandb.plot.line_series(\n",
        "                       xs=ranks, \n",
        "                       ys=errors,\n",
        "                       keys=types,\n",
        "                       title=f\"{name} error norm\",\n",
        "                       xname=\"rank\"\n",
        "                  ),\n",
        "       \n",
        "      f\"time-{name}\" : wandb.plot.line_series(\n",
        "                       xs=ranks, \n",
        "                       ys=times,\n",
        "                       keys=types,\n",
        "                       title=f\"{name} time (ms)\",\n",
        "                       xname=\"rank\"\n",
        "                  )\n",
        "      }\n",
        "      )"
      ],
      "metadata": {
        "id": "xXyL9w64bzzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97246bcf-4f7d-40aa-c293-d8561872e46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[36.77540283203125, 20.896495056152343, 10.179216766357422, 7.730741119384765, 3.4298431396484377], [30.323968505859376, 17.46246795654297, 9.938462066650391, 6.476787567138672, 3.8001636505126952]]\n",
            "[[1.5516704082489015, 2.1995775938034057, 2.158886396884918, 1.465715193748474, 1.578604805469513], [1.320252788066864, 1.2812000036239624, 1.4477215886116028, 1.7972896218299865, 2.637676811218262]]\n",
            "[[135.13428955078126, 150.11806640625, 41.65066223144531, 22.65662841796875, 14.275393676757812], [140.6180419921875, 61.96190185546875, 175.699951171875, 21.66957244873047, 17.7904541015625]]\n",
            "[[1.6030335903167725, 1.643011200428009, 1.8067488193511962, 1.7113599896430969, 1.8353087902069092], [2.294348806142807, 1.3887935996055603, 1.7988767862319945, 2.2847519874572755, 2.8212671995162966]]\n",
            "[[312.2346923828125, 114.4619873046875, 52.81734008789063, 43.312310791015626, 38.70779113769531], [335.914306640625, 94.18702392578125, 567.27490234375, 42.371701049804685, 49.84419250488281]]\n",
            "[[1.6395967960357667, 2.48441596031189, 2.3432480335235595, 2.082659196853638, 2.2088639974594115], [2.0166719913482667, 1.970684814453125, 2.5570207834243774, 2.488224005699158, 3.866918420791626]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qB_mXn1VDwJt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}